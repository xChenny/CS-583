{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. First Steps\n",
    "\n",
    "## 1.1 Load Data\n",
    "\n",
    "We use pandas to load data from `.csv` files into a Pandas Dataframe. We will utilize this dataframe to look at our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1175509, 3)\n",
      "(130613, 3)\n",
      "(375806, 2)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import gc\n",
    "\n",
    "# Get data from csv as pandas dataframe\n",
    "train_df = pd.read_csv('../input/train.csv')\n",
    "test_df = pd.read_csv('../input/test.csv')\n",
    "\n",
    "IN_DEVELOPMENT = False\n",
    "\n",
    "if IN_DEVELOPMENT:\n",
    "    # reduce the number of samples for quicker dev\n",
    "    train_df = train_df[:500000]\n",
    "    test_df = test_df[:150000]\n",
    "\n",
    "# split train data into validation and train data\n",
    "train_df, val_df = train_test_split(train_df, test_size=0.1, random_state=2018)\n",
    "\n",
    "print(train_df.shape)\n",
    "print(val_df.shape)\n",
    "print(test_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Analyze our Data\n",
    "\n",
    "Ideally, I want to look at our data and see if our training data is somehow skewed in a certain way. I seek answers to the following question(s):\n",
    "\n",
    "1. What is the proportion of insincere questions to sincere questions in our training data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2.1 What is the proportion of insincere questions to sincere questions in our training data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of target:\n",
      "Closer to 0 -> More Sincere Questions\n",
      "Closer to 1 -> More Insincere Questions\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.061832789030113765"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Mean of target:\")\n",
    "print(\"Closer to 0 -> More Sincere Questions\")\n",
    "print(\"Closer to 1 -> More Insincere Questions\")\n",
    "train_df.loc[:, \"target\"].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see from the results that there are significantly more sincere questions (mean = ~0.06). This can impact our model because a model that says that all questions are sincere would do pretty well here. (~93% correct)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Create Baseline Models For Comparison\n",
    "\n",
    "1. 50-50 Chance Random guessing\n",
    "2. Naively implemented Sentiment Analysis (Not Neural net-based)\n",
    "3. Model without pretrained word embedding layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.1 Random Guess Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5000293489883957\n"
     ]
    }
   ],
   "source": [
    "from random import randint\n",
    "\n",
    "def guess_model(data):\n",
    "    num_correct, num_samples = 0, 0\n",
    "    for sample in data:\n",
    "        prediction = randint(0, 1)\n",
    "        if prediction == sample:\n",
    "            num_correct += 1\n",
    "        num_samples += 1\n",
    "    return num_correct / num_samples\n",
    "\n",
    "train_data = train_df.loc[:, 'target']\n",
    "print(guess_model(train_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As one would expect, this model is roughly 50% accurate in binary classification. Let's see if we can do better with our other baseline models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.2 Naively Implemented Sentiment Analysis\n",
    "\n",
    "We will create a model that performs regular sentiment analysis (negative / positive), and hope that positive texts will correlate well to sincere texts, and likewise for negative texts to insincere texts.\n",
    "\n",
    "The way this implementation works is that it takes the polarity of each text as a whole if it's more positive, then this model's prediction will be that it is sincere, if not, then the model's prediction will be that it is not sincere.\n",
    "\n",
    "A caveat with this approach is that this model is unable to understand the relationship that words can have with each other. Meaning, that at the end of the day, we are looking at a word-by-word analysis of this text, and not considering the relationship of different words can have with each other that can alter the meaning of sentences.\n",
    "\n",
    "```\n",
    "ie: hang a man (negative. This basically means to kill a man)\n",
    "ie: hang man (neutral. This is a game, so not really negative.)\n",
    "```\n",
    "\n",
    "The previous two sentences share 2 words with each other, and have drastically different meanings and there are many other similar examples, so I expect that the accuracy of this model to be either around the same as the 50-50 model, or lower."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3695\n"
     ]
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "def sentiment_analysis_model(data):\n",
    "    num_correct, num_samples = 0, 0\n",
    "    for (text, label) in data:\n",
    "        sentiment = TextBlob(text).sentiment\n",
    "        # polarity is -1 to 1\n",
    "        polarity = (sentiment.polarity + 1) / 2\n",
    "        # we want to flip here: low polarity -> negative connotation, so we need to round and then flip values\n",
    "        prediction = 0 if round(polarity) == 1 else 1\n",
    "        if prediction == label:\n",
    "            num_correct += 1\n",
    "        num_samples += 1\n",
    "    return num_correct / num_samples\n",
    "        \n",
    "# the textblob library takes quite a bit of time, so we limit our samples to 10000\n",
    "sent_analysis_data = train_df.loc[:, ['question_text', 'target']].values[:10000]\n",
    "\n",
    "print(sentiment_analysis_model(sent_analysis_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model's accuracy is quite low (~36%), which I suppose has to do with a low correlation between sentiment (positive/negative) and sincerity in texts as well as the aforementioned caveat in the previous markdown cell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3.3 Deep Learning Model without pretrained embedding layer\n",
    "\n",
    "This model is below in section 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1450"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cleanup any unused vars\n",
    "del sent_analysis_data, train_data\n",
    "# manually use garbage collector to clean up any unused variables\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "from unicodedata import normalize\n",
    "import re\n",
    "import string\n",
    "\n",
    "# Preprocess Sentences\n",
    "def clean_data(lines):\n",
    "    cleaned = list()\n",
    "    # prepare regex for char filtering\n",
    "    re_print = re.compile('[^%s]' % re.escape(string.printable))\n",
    "    # prepare translation table for removing punctuation\n",
    "    table = str.maketrans('', '', string.punctuation)\n",
    "    max_length = 0\n",
    "    for line in lines:\n",
    "        # normalize unicode characters\n",
    "        line = normalize('NFD', line).encode('ascii', 'ignore')\n",
    "        line = line.decode('UTF-8')\n",
    "        # tokenize on white space\n",
    "        line = line.split()\n",
    "        # convert to lowercase\n",
    "        line = [word.lower() for word in line]\n",
    "        # remove punctuation from each token\n",
    "        line = [word.translate(table) for word in line]\n",
    "        # remove non-printable chars form each token\n",
    "        line = [re_print.sub('', w) for w in line]\n",
    "        # remove tokens with numbers in them\n",
    "        line = [word for word in line if word.isalpha()]\n",
    "        length = len(line)\n",
    "        if length > max_length:\n",
    "            max_length = length\n",
    "        # store as string\n",
    "        line = ' '.join(line)\n",
    "        cleaned.append(line)\n",
    "    return np.array(cleaned), max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what have been the best exhibits at the museo del prado in madrid\n",
      "how can i rotate batch image files\n",
      "which is the best cable operator in thane west area\n",
      "how do i expand factor and simplify in algebra\n",
      "do you judge people often\n",
      "how do i get above in icse in all subjects in\n",
      "how do i use the grid method\n",
      "can you hang a poster diagonally if you have a good reason for it\n",
      "do many bulgarians consider macedonia part of bulgaria\n",
      "did you have any superb business india on your mind\n"
     ]
    }
   ],
   "source": [
    "# fill up the missing values\n",
    "train_X = train_df[\"question_text\"].fillna(\"_na_\").values\n",
    "val_X = val_df[\"question_text\"].fillna(\"_na_\").values\n",
    "test_X = test_df[\"question_text\"].fillna(\"_na_\").values\n",
    "\n",
    "train_X, max_len_trainX = clean_data(train_X)\n",
    "val_X, max_len_valX = clean_data(val_X)\n",
    "test_X, max_len_testX = clean_data(test_X)\n",
    "\n",
    "for i in range(10):\n",
    "    print(train_X[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Text to Sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Define tunable parameters for preprocessing texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## some config values \n",
    "embed_size = 300 # how big is each word vector\n",
    "max_features = 50000 # how many unique words to use (i.e num rows in embedding vector)\n",
    "maxlen = 100 # max number of words in a question to use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Preprocess Texts\n",
    "\n",
    "We use the keras `preprocessing` module to tokenize (`preprocessing.text.Tokenizer`) our text and then pad our resulting sequences with 0's at the end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished fitting tokenizer! Turning texts to sequences...\n",
      "Finished turning texts to sequences! Padding sequences...\n",
      "Finished padding sequences! Getting target labels...\n",
      "Finished getting target labels!\n",
      "\n",
      "shape of train_seq_X: (1175509, 100)\n",
      "shape of val_seq_X: (130613, 100)\n",
      "shape of test_seq_X: (375806, 100)\n",
      "shape of train_Y: (1175509,)\n",
      "shape of val_Y: (130613,)\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# word-level tokenizing\n",
    "tokenizer = Tokenizer(num_words=max_features)\n",
    "\n",
    "# train tokenizer\n",
    "tokenizer.fit_on_texts(list(train_X))\n",
    "print(\"Finished fitting tokenizer! Turning texts to sequences...\")\n",
    "\n",
    "# tokenized texts -> sequences\n",
    "train_seq_X = tokenizer.texts_to_sequences(train_X)\n",
    "val_seq_X = tokenizer.texts_to_sequences(val_X)\n",
    "test_seq_X = tokenizer.texts_to_sequences(test_X)\n",
    "print(\"Finished turning texts to sequences! Padding sequences...\")\n",
    "\n",
    "# pad sequences\n",
    "train_seq_X = pad_sequences(train_seq_X, maxlen=maxlen, padding='post')\n",
    "val_seq_X = pad_sequences(val_seq_X, maxlen=maxlen, padding='post')\n",
    "test_seq_X = pad_sequences(test_seq_X, maxlen=maxlen, padding='post')\n",
    "print(\"Finished padding sequences! Getting target labels...\")\n",
    "\n",
    "# get target labels\n",
    "train_Y = train_df[\"target\"].values\n",
    "val_Y = val_df[\"target\"].values\n",
    "print(\"Finished getting target labels!\\n\")\n",
    "\n",
    "print(\"shape of train_seq_X:\", train_seq_X.shape)\n",
    "print(\"shape of val_seq_X:\", val_seq_X.shape)\n",
    "print(\"shape of test_seq_X:\", test_seq_X.shape)\n",
    "\n",
    "print(\"shape of train_Y:\", train_Y.shape)\n",
    "print(\"shape of val_Y:\", val_Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataframes and texts already deleted!\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    del train_df, val_df, train_X, val_X, test_X\n",
    "    import gc; gc.collect()\n",
    "    time.sleep(10)\n",
    "    print(\"cleaned dataframes and texts!\")\n",
    "except NameError:\n",
    "    print(\"dataframes and texts already deleted!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Embedding, Creating and Training Model\n",
    "\n",
    "We create a matrix of word associations in relationship to our texts.\n",
    "\n",
    "## 4.1 Creating Embedding Dictionaries from Supplied Files\n",
    "\n",
    "For this part: I referred to intuitions made in this [kernel](https://www.kaggle.com/sudalairajkumar/a-look-at-different-embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embedding\n",
    "PARAGRAM_EMBED = '../input/embeddings/paragram_300_sl999/paragram_300_sl999.txt'\n",
    "WIKI_NEWS_EMBED = '../input/embeddings/wiki-news-300d-1M/wiki-news-300d-1M.vec'\n",
    "GLOVE_EMBED = '../input/embeddings/glove.840B.300d/glove.840B.300d.txt'\n",
    "\n",
    "def get_embeddings(file):\n",
    "    \"\"\"return as a numpy array the coefficients of word embeddings from a file\"\"\"\n",
    "    def get_coefs(word,*arr): \n",
    "        return word, np.asarray(arr, dtype='float32')\n",
    "    \n",
    "    if \"glove\" in file:\n",
    "        return dict(get_coefs(*o.split(\" \")) for o in open(file))\n",
    "    elif \"wiki\" in file:\n",
    "        return dict(get_coefs(*o.split(\" \")) for o in open(file) if len(o) > 100)\n",
    "    elif \"paragram\" in file:\n",
    "        return dict(get_coefs(*o.split(\" \")) for o in open(file, encoding=\"utf8\", errors='ignore') if len(o) > 100)\n",
    "    else:\n",
    "        print(\"invalid embeddings file\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Create model\n",
    "\n",
    "Here, we use the embedding that we created in the cell before to create a model with an embedding layer whose weights we will use the embedding from the supplied files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Embedding, Dense, Input, LSTM, Embedding\n",
    "from keras.layers import Dropout, Activation, CuDNNGRU, Conv1D, Bidirectional, GlobalMaxPool1D\n",
    "from keras.models import Model\n",
    "\n",
    "def create_model(embedding_matrix, embed_size, maxlen=maxlen, max_features=max_features):\n",
    "    \"\"\"Create model for binary classification of texts as insincere vs. not insincere\"\"\"\n",
    "    inp = Input(shape=(maxlen,))\n",
    "    if embedding_matrix is not None:\n",
    "        x = Embedding(max_features, embed_size, weights=[embedding_matrix])(inp)\n",
    "    else:\n",
    "        x = Embedding(max_features, embed_size)(inp)\n",
    "    x = Bidirectional(CuDNNGRU(64, return_sequences=True))(x)\n",
    "    x = GlobalMaxPool1D()(x)\n",
    "    x = Dense(16, activation=\"relu\")(x)\n",
    "    x = Dropout(0.1)(x)\n",
    "    x = Dense(1, activation=\"sigmoid\")(x)\n",
    "    model = Model(inputs=inp, outputs=x)\n",
    "    return model\n",
    "\n",
    "def setup_model(embeddings_index, tokenizer, embed_size):\n",
    "    \"\"\"Extract necessary components of embedding dictionaries and create a model\"\"\"\n",
    "    if not embeddings_index:\n",
    "        return create_model(None, embed_size)\n",
    "    all_embs = np.stack(embeddings_index.values())\n",
    "    emb_mean,emb_std = all_embs.mean(), all_embs.std()\n",
    "    embed_size = all_embs.shape[1]\n",
    "\n",
    "    word_index = tokenizer.word_index\n",
    "    nb_words = min(max_features, len(word_index))\n",
    "    embedding_matrix = np.random.normal(emb_mean, emb_std, (nb_words, embed_size))\n",
    "    for word, i in word_index.items():\n",
    "        if i >= max_features: \n",
    "            continue\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None: \n",
    "            embedding_matrix[i] = embedding_vector\n",
    "            \n",
    "    # create model        \n",
    "    return create_model(embedding_matrix, embed_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 Compile and Train our Model\n",
    "\n",
    "We get our word embeddings, then create, compile and train models. After each test, we clean out our memory, so that we can train another model without incurring massive memory usage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3.1 Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baseline model:\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 100, 300)          15000000  \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 100, 128)          140544    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 16)                2064      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 15,142,625\n",
      "Trainable params: 15,142,625\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# No pretrained word embeddings here.\n",
    "\n",
    "print(\"baseline model:\")\n",
    "baseline_model = setup_model(None, tokenizer, embed_size)\n",
    "baseline_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile model\n",
    "baseline_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "Train on 1175509 samples, validate on 130613 samples\n",
      "Epoch 1/2\n",
      "1175509/1175509 [==============================] - 91s 78us/step - loss: 0.1214 - acc: 0.9537 - val_loss: 0.1077 - val_acc: 0.9571\n",
      "Epoch 2/2\n",
      "1175509/1175509 [==============================] - 88s 74us/step - loss: 0.0982 - acc: 0.9606 - val_loss: 0.1072 - val_acc: 0.9572\n"
     ]
    }
   ],
   "source": [
    "# Fit Model\n",
    "history = baseline_model.fit(train_seq_X, train_Y, batch_size=512, epochs=2, validation_data=(val_seq_X, val_Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(loss))\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training Loss')\n",
    "plt.plot(epochs, val_loss, 'r', label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130613/130613 [==============================] - 2s 16us/step\n"
     ]
    }
   ],
   "source": [
    "# Make a Prediction on the validation data set\n",
    "pred_base_val_y = baseline_model.predict([val_seq_X], batch_size=1024, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# do some cleanup\n",
    "try:\n",
    "    del baseline_model\n",
    "    import gc; gc.collect()\n",
    "    time.sleep(10)\n",
    "except NameError:\n",
    "    print(\"baseline_model already deleted!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3.2 Paragram Word Embeddings Model\n",
    "\n",
    "We use the weights obtained from the paragram word embeddings for our embedding layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading paragram embeddings...\n",
      "checking if we already created paragram embeddings dict...\n",
      "we did not... creating paragram embeddings dictionary\n",
      "paragram model:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:24: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "embedding_2 (Embedding)      (None, 100, 300)          15000000  \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (None, 100, 128)          140544    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_2 (Glob (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 16)                2064      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 15,142,625\n",
      "Trainable params: 15,142,625\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Embedding indices of embedding file\n",
    "print(\"Loading paragram embeddings...\")\n",
    "try:\n",
    "    print(\"checking if we already created paragram embeddings dict...\")\n",
    "    paragram_embed_index\n",
    "    print(\"we already created it\")\n",
    "except NameError:\n",
    "    print(\"we did not... creating paragram embeddings dictionary\")\n",
    "    paragram_embed_index = get_embeddings(PARAGRAM_EMBED)\n",
    "\n",
    "# create model with embedding layer based on pretrained weights from paragram word embedding\n",
    "print(\"paragram model:\")\n",
    "paragram_model = setup_model(paragram_embed_index, tokenizer, embed_size)\n",
    "paragram_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile\n",
    "paragram_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1175509 samples, validate on 130613 samples\n",
      "Epoch 1/2\n",
      "1175509/1175509 [==============================] - 90s 77us/step - loss: 0.1171 - acc: 0.9538 - val_loss: 0.1032 - val_acc: 0.9587\n",
      "Epoch 2/2\n",
      "1175509/1175509 [==============================] - 87s 74us/step - loss: 0.0960 - acc: 0.9620 - val_loss: 0.1019 - val_acc: 0.9592\n"
     ]
    }
   ],
   "source": [
    "# Fit Model\n",
    "history = paragram_model.fit(train_seq_X, train_Y, batch_size=512, epochs=2, validation_data=(val_seq_X, val_Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(loss))\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training Loss')\n",
    "plt.plot(epochs, val_loss, 'r', label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130613/130613 [==============================] - 2s 17us/step\n",
      "375806/375806 [==============================] - 6s 15us/step\n"
     ]
    }
   ],
   "source": [
    "# Make a Prediction on the validation data set\n",
    "pred_paragram_val_y = paragram_model.predict([val_seq_X], batch_size=1024, verbose=1)\n",
    "# Make a Prediction on the test data set\n",
    "pred_paragram_test_y = paragram_model.predict([test_seq_X], batch_size=1024, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cleaned baseline_model vars!\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    del paragram_embed_index, paragram_model\n",
    "    gc.collect()\n",
    "    time.sleep(10)\n",
    "    print(\"cleaned baseline_model vars!\")\n",
    "except NameError:\n",
    "    print(\"baseline_model already deleted!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3.3 Glove Word Embeddings\n",
    "\n",
    "We use the weights obtained from the glove word embeddings for our embedding layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading glove embeddings...\n",
      "checking if we already created glove embeddings dict...\n",
      "we did not... creating glove embeddings dictionary\n",
      "glove model:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:24: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "embedding_3 (Embedding)      (None, 100, 300)          15000000  \n",
      "_________________________________________________________________\n",
      "bidirectional_3 (Bidirection (None, 100, 128)          140544    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_3 (Glob (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 16)                2064      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 15,142,625\n",
      "Trainable params: 15,142,625\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Embedding indices of embedding file\n",
    "print(\"Loading glove embeddings...\")\n",
    "try:\n",
    "    print(\"checking if we already created glove embeddings dict...\")\n",
    "    glove_embed_index\n",
    "    print(\"we already created it\")\n",
    "except NameError:\n",
    "    print(\"we did not... creating glove embeddings dictionary\")\n",
    "    glove_embed_index = get_embeddings(GLOVE_EMBED)\n",
    "\n",
    "# create model with embedding layer based on pretrained weights from paragram word embedding\n",
    "print(\"glove model:\")\n",
    "glove_model = setup_model(glove_embed_index, tokenizer, embed_size)\n",
    "glove_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile\n",
    "glove_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1175509 samples, validate on 130613 samples\n",
      "Epoch 1/2\n",
      "1175509/1175509 [==============================] - 89s 76us/step - loss: 0.1120 - acc: 0.9564 - val_loss: 0.1022 - val_acc: 0.9586\n",
      "Epoch 2/2\n",
      "1175509/1175509 [==============================] - 86s 74us/step - loss: 0.0929 - acc: 0.9629 - val_loss: 0.1007 - val_acc: 0.9596\n"
     ]
    }
   ],
   "source": [
    "# Fit Model\n",
    "history = glove_model.fit(train_seq_X, train_Y, batch_size=512, epochs=2, validation_data=(val_seq_X, val_Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(loss))\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training Loss')\n",
    "plt.plot(epochs, val_loss, 'r', label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130613/130613 [==============================] - 2s 19us/step\n",
      "375806/375806 [==============================] - 6s 15us/step\n"
     ]
    }
   ],
   "source": [
    "# Make a Prediction on the validation data set\n",
    "pred_glove_val_y = glove_model.predict([val_seq_X], batch_size=1024, verbose=1)\n",
    "# Make a Prediction on the test data set\n",
    "pred_glove_test_y = glove_model.predict([test_seq_X], batch_size=1024, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cleaned baseline_model vars!\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    del glove_embed_index, glove_model\n",
    "    import gc; gc.collect()\n",
    "    time.sleep(10)\n",
    "    print(\"cleaned baseline_model vars!\")\n",
    "except NameError:\n",
    "    print(\"baseline_model already deleted!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4.4 Wiki News Word Embedding Model\n",
    "\n",
    "We use the weights obtained from the glove word embeddings for our embedding layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading wiki embeddings...\n",
      "checking if we already created wiki embeddings dict...\n",
      "we did not... creating wiki embeddings dictionary\n",
      "wikinews model:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:24: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "embedding_4 (Embedding)      (None, 100, 300)          15000000  \n",
      "_________________________________________________________________\n",
      "bidirectional_4 (Bidirection (None, 100, 128)          140544    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_4 (Glob (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 16)                2064      \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 15,142,625\n",
      "Trainable params: 15,142,625\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Embedding indices of embedding file\n",
    "print(\"Loading wiki embeddings...\")\n",
    "try:\n",
    "    print(\"checking if we already created wiki embeddings dict...\")\n",
    "    wiki_embed_index\n",
    "    print(\"we already created it\")\n",
    "except NameError:\n",
    "    print(\"we did not... creating wiki embeddings dictionary\")\n",
    "    wiki_embed_index = get_embeddings(WIKI_NEWS_EMBED)\n",
    "\n",
    "# create model with embedding layer based on pretrained weights from paragram word embedding\n",
    "print(\"wikinews model:\")\n",
    "wikinews_model = setup_model(wiki_embed_index, tokenizer, embed_size)\n",
    "wikinews_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile\n",
    "wikinews_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1175509 samples, validate on 130613 samples\n",
      "Epoch 1/2\n",
      "1175509/1175509 [==============================] - 89s 76us/step - loss: 0.1169 - acc: 0.9554 - val_loss: 0.1042 - val_acc: 0.9586\n",
      "Epoch 2/2\n",
      "1175509/1175509 [==============================] - 87s 74us/step - loss: 0.0942 - acc: 0.9628 - val_loss: 0.1035 - val_acc: 0.9591\n"
     ]
    }
   ],
   "source": [
    "# Fit Model\n",
    "history = wikinews_model.fit(train_seq_X, train_Y, batch_size=512, epochs=2, validation_data=(val_seq_X, val_Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(loss))\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training Loss')\n",
    "plt.plot(epochs, val_loss, 'r', label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130613/130613 [==============================] - 2s 18us/step\n",
      "375806/375806 [==============================] - 6s 15us/step\n"
     ]
    }
   ],
   "source": [
    "# Make a Prediction on the validation data set\n",
    "pred_wiki_val_y = wikinews_model.predict([val_seq_X], batch_size=1024, verbose=1)\n",
    "# Make a Prediction on the test data set\n",
    "pred_wiki_test_y = wikinews_model.predict([test_seq_X], batch_size=1024, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cleaned wikinews_model vars!\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    del wiki_embed_index, wikinews_model\n",
    "    import gc; gc.collect()\n",
    "    time.sleep(10)\n",
    "    print(\"cleaned wikinews_model vars!\")\n",
    "except NameError:\n",
    "    print(\"wikinews_model already deleted!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4 Analyze the Results\n",
    "\n",
    "Here, we use the f1-score metric to compare the baseline model with using 1 of each provided word embedding, and see which is the best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best scores are:\n",
      "\n",
      "The best score for baseline model:\n",
      "Threshold: 0.32\n",
      "F1 score: 0.6548850735417483\n",
      "\n",
      "\n",
      "The best score for paragram model:\n",
      "Threshold: 0.34\n",
      "F1 score: 0.6746744499326448\n",
      "\n",
      "\n",
      "The best score for glove model:\n",
      "Threshold: 0.35\n",
      "F1 score: 0.6774870892684866\n",
      "\n",
      "\n",
      "The best score for wiki news model\n",
      "Threshold: 0.31\n",
      "F1 score: 0.6737046336452864\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "\n",
    "preds = [pred_base_val_y, pred_paragram_val_y, pred_glove_val_y, pred_wiki_val_y]\n",
    "pred_labels = ['baseline model:', 'paragram model:', 'glove model:', 'wiki news model']\n",
    "model_predictions = zip(preds, pred_labels)\n",
    "\n",
    "# Analyze results\n",
    "# The F1 score can be interpreted as a weighted average of the precision and recall\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html\n",
    "best_scores = []\n",
    "for (pred, label) in model_predictions:\n",
    "    best_thresh, best_f1_score = 0, 0\n",
    "#     print(label)\n",
    "    for thresh in np.arange(0.1, 0.501, 0.01):\n",
    "        curr_thresh = np.round(thresh, 2)\n",
    "        curr_f1 = f1_score(val_Y,(pred>thresh).astype(int))\n",
    "        if curr_f1 > best_f1_score:\n",
    "            best_thresh = curr_thresh\n",
    "            best_f1_score = curr_f1\n",
    "#         print(\"F1 score at threshold {0} is {1}\".format(curr_thresh, curr_f1))\n",
    "    best_scores.append([best_thresh, best_f1_score])\n",
    "#     print('\\n')\n",
    "    \n",
    "print(\"The best scores are:\\n\")\n",
    "for ((thresh, f1), label) in zip(best_scores, pred_labels):\n",
    "    print(\"The best score for {0}\".format(label))\n",
    "    print(\"Threshold:\", thresh)\n",
    "    print(\"F1 score:\", f1)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, we saw that the best word embedding to use was the glove word embeddings with a f1 score of ~0.66-7. Below, we check and see if we can improve on this using ensembling methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best score for ensemble\n",
      "Threshold: 0.35\n",
      "F1 score: 0.6848904267589389\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# take some of the results from each embedding model.\n",
    "pred_ensemble_val_y = 0.33 * pred_paragram_val_y + 0.33 * pred_glove_val_y + 0.34 * pred_wiki_val_y\n",
    "best_thresh, best_f1_score = 0, 0\n",
    "for thresh in np.arange(0.1, 0.501, 0.01):\n",
    "    curr_thresh = np.round(thresh, 2)\n",
    "    curr_f1 = f1_score(val_Y,(pred_ensemble_val_y>thresh).astype(int))    \n",
    "    if curr_f1 > best_f1_score:\n",
    "        best_thresh = curr_thresh\n",
    "        best_f1_score = curr_f1\n",
    " \n",
    "print(\"The best score for ensemble\")\n",
    "print(\"Threshold:\", best_thresh)\n",
    "print(\"F1 score:\", best_f1_score)\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we used a mix of the results of all three word embeddings and found that the result is actually just a little better (~0.01 improvement) than just using one. Perhaps this is due to each of the models capturing something a little different from each other, and therefore, using ensembling here works although, it may not be worth the extra time in training the other two models because the improvement from using the glove model to ensembling methods is almost negligible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 Create Test Submission\n",
    "\n",
    "Up to this point, we've preprocessed text, turned it into a sequence, padded it, loaded embeddings, created a model, trained it, and then tested/tuned it for optimal performance.\n",
    "\n",
    "Now, all I have to do is to use this model that I've trained and create a submission for this competition.\n",
    "\n",
    "I already used the last three models to predict the values of the test set when I created the predictions on the validation set. Now, we just need to use them.\n",
    "\n",
    "As determined by the last test, we will use our best method, the ensembling model predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_ensemble_test_y = 0.33 * pred_paragram_test_y + 0.33 * pred_glove_test_y + 0.34 * pred_wiki_test_y\n",
    "\n",
    "# round values to 0 / 1\n",
    "y_te = (np.array(pred_ensemble_test_y) > 0.5).astype(np.int).reshape(len(pred_ensemble_test_y),)\n",
    "\n",
    "# create dataframe of [\"qid\", \"prediction\"]\n",
    "submit_df = pd.DataFrame({\"qid\": test_df[\"qid\"], \"prediction\": y_te})\n",
    "\n",
    "# create .csv file\n",
    "submit_df.to_csv(\"submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
