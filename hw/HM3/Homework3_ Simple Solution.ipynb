{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Home 3: Build a CNN for image recognition.\n",
    "\n",
    "### Name: Andrew Chen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. You will do the following:\n",
    "\n",
    "1. Read, complete, and run my code.\n",
    "\n",
    "2. **Make substantial improvements** to maximize the accurcy.\n",
    "    \n",
    "3. Convert the .IPYNB file to .HTML file.\n",
    "\n",
    "    * The HTML file must contain the code and the output after execution.\n",
    "    \n",
    "4. Upload this .HTML file to your Github repo.\n",
    "\n",
    "4. Submit the link to this .HTML file to Canvas.\n",
    "\n",
    "    * Example: https://github.com/wangshusen/CS583A-2019Spring/blob/master/homework/HM3/cnn.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Load data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of x_train: (50000, 32, 32, 3)\n",
      "shape of y_train: (50000, 1)\n",
      "shape of x_test: (10000, 32, 32, 3)\n",
      "shape of y_test: (10000, 1)\n",
      "number of classes: 10\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import cifar10\n",
    "from keras.utils import to_categorical\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras import optimizers\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "print('shape of x_train: ' + str(x_train.shape))\n",
    "print('shape of y_train: ' + str(y_train.shape))\n",
    "print('shape of x_test: ' + str(x_test.shape))\n",
    "print('shape of y_test: ' + str(y_test.shape))\n",
    "print('number of classes: ' + str(np.max(y_train) - np.min(y_train) + 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. One-hot encode the labels\n",
    "\n",
    "In the input, a label is a scalar in $\\{0, 1, \\cdots , 9\\}$. One-hot encode transform such a scalar to a $10$-dim vector. E.g., a scalar ```y_train[j]=3``` is transformed to the vector ```y_train_vec[j]=[0, 0, 0, 1, 0, 0, 0, 0, 0, 0]```.\n",
    "\n",
    "1. Define a function ```to_one_hot``` that transforms an $n\\times 1$ array to a $n\\times 10$ matrix.\n",
    "\n",
    "2. Apply the function to ```y_train``` and ```y_test```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of y_train_vec: (50000, 10)\n",
      "Shape of y_test_vec: (10000, 10)\n",
      "[6]\n",
      "[0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "def to_one_hot(y, num_class=10):\n",
    "    return to_categorical(y, num_classes=num_class)\n",
    "\n",
    "y_train_vec = to_one_hot(y_train)\n",
    "y_test_vec = to_one_hot(y_test)\n",
    "\n",
    "print('Shape of y_train_vec: ' + str(y_train_vec.shape))\n",
    "print('Shape of y_test_vec: ' + str(y_test_vec.shape))\n",
    "\n",
    "print(y_train[0])\n",
    "print(y_train_vec[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remark: the outputs should be\n",
    "* Shape of y_train_vec: (50000, 10)\n",
    "* Shape of y_test_vec: (10000, 10)\n",
    "* [6]\n",
    "* [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Randomly partition the training set to training and validation sets\n",
    "\n",
    "Randomly partition the 50K training samples to 2 sets:\n",
    "* a training set containing 40K samples\n",
    "* a validation set containing 10K samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of x_tr: (40000, 32, 32, 3)\n",
      "Shape of y_tr: (40000, 10)\n",
      "Shape of x_val: (10000, 32, 32, 3)\n",
      "Shape of y_val: (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "rand_indices = np.random.permutation(50000)\n",
    "train_indices = rand_indices[0:40000]\n",
    "valid_indices = rand_indices[40000:50000]\n",
    "\n",
    "x_val = x_train[valid_indices, :]\n",
    "y_val = y_train_vec[valid_indices, :]\n",
    "\n",
    "x_tr = x_train[train_indices, :]\n",
    "y_tr = y_train_vec[train_indices, :]\n",
    "\n",
    "print('Shape of x_tr: ' + str(x_tr.shape))\n",
    "print('Shape of y_tr: ' + str(y_tr.shape))\n",
    "print('Shape of x_val: ' + str(x_val.shape))\n",
    "print('Shape of y_val: ' + str(y_val.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Build a CNN and tune its hyper-parameters\n",
    "\n",
    "1. Build a convolutional neural network model\n",
    "2. Use the validation data to tune the hyper-parameters (e.g., network structure, and optimization algorithm)\n",
    "    * Do NOT use test data for hyper-parameter tuning!!!\n",
    "3. Try to achieve a validation accuracy as high as possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remark: \n",
    "\n",
    "The following CNN is just an example. You are supposed to make **substantial improvements** such as:\n",
    "* Add more layers.\n",
    "* Use regularizations, e.g., dropout.\n",
    "* Use batch normalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Activation, BatchNormalization, Dropout\n",
    "from keras.models import Sequential\n",
    "\n",
    "def build_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), padding='same', input_shape=(32, 32, 3)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    \n",
    "    model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    \n",
    "    model.add(Conv2D(128, (3, 3), padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    \n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    model.add(Conv2D(256, (3, 3), padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Augmentation\n",
    "\n",
    "We use data augmentation to increase the number of training samples we can utilize to train our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# data augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Our Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1E-4 # to be tuned!\n",
    "batch_size = 128\n",
    "epochs = 150\n",
    "steps_per_epoch = len(x_tr) // batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's Find the Optimal Hyperparameters!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model()\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizers.RMSprop(lr=learning_rate),\n",
    "              metrics=['acc'])\n",
    "\n",
    "history = model.fit_generator(datagen.flow(x_tr, y_tr, batch_size=batch_size),\n",
    "                              steps_per_epoch=steps_per_epoch,\n",
    "                              epochs=epochs,\n",
    "                              validation_data=(x_val, y_val))\n",
    "model.save('cifar10.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's plot our results for these Hyper Parameters..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'r', label='Validation acc')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparamter Tuning Model Results\n",
    "\n",
    "The rate that the accuracy is changing is logarithmic. I suspect that if I had ran more epochs, I would be able to get better performance, but at this point, 150 epochs is enough because I suspect that the improvement in accuracy is minimal per additional epoch due to its logarithmic shape.\n",
    "\n",
    "My final results:\n",
    "\n",
    "training accuracy: ~73%\n",
    "\n",
    "validation accuracy: ~75%\n",
    "\n",
    "![image.png](attachment:image.png)\n",
    "\n",
    "When training I seemed to have my validation always be higher than my training accuracy. I didn't have the time to test it out, but I suspect that my validation data (regular x_val, y_val), which is not being augmented, lacks the variety that my training data (which is being augmented) is subject to."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train (again) and evaluate the model\n",
    "\n",
    "- To this end, you have found the \"best\" hyper-parameters. \n",
    "- Now, fix the hyper-parameters and train the network on the entire training set (all the 50K training samples)\n",
    "- Evaluate your model on the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. Train the model on the entire training set\n",
    "\n",
    "Why? Previously, you used 40K samples for training; you wasted 10K samples for the sake of hyper-parameter tuning. Now you already know the hyper-parameters, so why not using all the 50K samples for training?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 16, 16, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 16, 16, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 8, 8, 128)         73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 8, 8, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 4, 4, 256)         295168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 4, 4, 256)         1024      \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 2, 2, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               131200    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 539,338\n",
      "Trainable params: 538,378\n",
      "Non-trainable params: 960\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "final_model = build_model()\n",
    "\n",
    "final_model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizers.RMSprop(lr=learning_rate),\n",
    "              metrics=['acc'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/150\n",
      "312/312 [==============================] - 26s 84ms/step - loss: 2.0991 - acc: 0.2264\n",
      "Epoch 2/150\n",
      "312/312 [==============================] - 23s 74ms/step - loss: 1.8700 - acc: 0.2985\n",
      "Epoch 3/150\n",
      "312/312 [==============================] - 22s 72ms/step - loss: 1.7712 - acc: 0.3402\n",
      "Epoch 4/150\n",
      "312/312 [==============================] - 22s 72ms/step - loss: 1.7027 - acc: 0.3682\n",
      "Epoch 5/150\n",
      "312/312 [==============================] - 22s 72ms/step - loss: 1.6602 - acc: 0.3845\n",
      "Epoch 6/150\n",
      "312/312 [==============================] - 22s 72ms/step - loss: 1.6268 - acc: 0.4001\n",
      "Epoch 7/150\n",
      "312/312 [==============================] - 22s 71ms/step - loss: 1.5863 - acc: 0.4160\n",
      "Epoch 8/150\n",
      "312/312 [==============================] - 22s 72ms/step - loss: 1.5483 - acc: 0.4294\n",
      "Epoch 9/150\n",
      "312/312 [==============================] - 23s 72ms/step - loss: 1.5316 - acc: 0.4379\n",
      "Epoch 10/150\n",
      "312/312 [==============================] - 23s 73ms/step - loss: 1.5040 - acc: 0.4501\n",
      "Epoch 11/150\n",
      "312/312 [==============================] - 22s 72ms/step - loss: 1.4734 - acc: 0.4623\n",
      "Epoch 12/150\n",
      "312/312 [==============================] - 22s 72ms/step - loss: 1.4500 - acc: 0.4715\n",
      "Epoch 13/150\n",
      "312/312 [==============================] - 22s 72ms/step - loss: 1.4238 - acc: 0.4822\n",
      "Epoch 14/150\n",
      "312/312 [==============================] - 22s 72ms/step - loss: 1.4042 - acc: 0.4890\n",
      "Epoch 15/150\n",
      "312/312 [==============================] - 22s 71ms/step - loss: 1.3914 - acc: 0.4923\n",
      "Epoch 16/150\n",
      "312/312 [==============================] - 23s 73ms/step - loss: 1.3697 - acc: 0.5039\n",
      "Epoch 17/150\n",
      "312/312 [==============================] - 22s 71ms/step - loss: 1.3580 - acc: 0.5104\n",
      "Epoch 18/150\n",
      "312/312 [==============================] - 22s 71ms/step - loss: 1.3479 - acc: 0.5140\n",
      "Epoch 19/150\n",
      "312/312 [==============================] - 22s 71ms/step - loss: 1.3297 - acc: 0.5205\n",
      "Epoch 20/150\n",
      "312/312 [==============================] - 22s 71ms/step - loss: 1.3101 - acc: 0.5278\n",
      "Epoch 21/150\n",
      "312/312 [==============================] - 22s 71ms/step - loss: 1.3073 - acc: 0.5294\n",
      "Epoch 22/150\n",
      "312/312 [==============================] - 22s 71ms/step - loss: 1.2962 - acc: 0.5368\n",
      "Epoch 23/150\n",
      "312/312 [==============================] - 22s 71ms/step - loss: 1.2837 - acc: 0.5357\n",
      "Epoch 24/150\n",
      "312/312 [==============================] - 23s 72ms/step - loss: 1.2711 - acc: 0.5451\n",
      "Epoch 25/150\n",
      "312/312 [==============================] - 22s 71ms/step - loss: 1.2610 - acc: 0.5493\n",
      "Epoch 26/150\n",
      "312/312 [==============================] - 22s 71ms/step - loss: 1.2452 - acc: 0.5544\n",
      "Epoch 27/150\n",
      "312/312 [==============================] - 22s 71ms/step - loss: 1.2410 - acc: 0.5526\n",
      "Epoch 28/150\n",
      "312/312 [==============================] - 22s 71ms/step - loss: 1.2407 - acc: 0.5574\n",
      "Epoch 29/150\n",
      "312/312 [==============================] - 22s 70ms/step - loss: 1.2180 - acc: 0.5677\n",
      "Epoch 30/150\n",
      "312/312 [==============================] - 23s 73ms/step - loss: 1.2130 - acc: 0.5660\n",
      "Epoch 31/150\n",
      "312/312 [==============================] - 22s 71ms/step - loss: 1.2068 - acc: 0.5702\n",
      "Epoch 32/150\n",
      "312/312 [==============================] - 22s 71ms/step - loss: 1.1908 - acc: 0.5752\n",
      "Epoch 33/150\n",
      "312/312 [==============================] - 22s 71ms/step - loss: 1.1820 - acc: 0.5791\n",
      "Epoch 34/150\n",
      "312/312 [==============================] - 22s 71ms/step - loss: 1.1760 - acc: 0.5803\n",
      "Epoch 35/150\n",
      "312/312 [==============================] - 22s 71ms/step - loss: 1.1724 - acc: 0.5851\n",
      "Epoch 36/150\n",
      "312/312 [==============================] - 22s 72ms/step - loss: 1.1676 - acc: 0.5842\n",
      "Epoch 37/150\n",
      "312/312 [==============================] - 22s 72ms/step - loss: 1.1541 - acc: 0.5890\n",
      "Epoch 38/150\n",
      "312/312 [==============================] - 22s 71ms/step - loss: 1.1501 - acc: 0.5897\n",
      "Epoch 39/150\n",
      "312/312 [==============================] - 22s 71ms/step - loss: 1.1457 - acc: 0.5922\n",
      "Epoch 40/150\n",
      "312/312 [==============================] - 22s 71ms/step - loss: 1.1368 - acc: 0.5981\n",
      "Epoch 41/150\n",
      "312/312 [==============================] - 22s 71ms/step - loss: 1.1307 - acc: 0.5985\n",
      "Epoch 42/150\n",
      "312/312 [==============================] - 22s 71ms/step - loss: 1.1211 - acc: 0.6049\n",
      "Epoch 43/150\n",
      "312/312 [==============================] - 22s 71ms/step - loss: 1.1159 - acc: 0.6041\n",
      "Epoch 44/150\n",
      "312/312 [==============================] - 23s 73ms/step - loss: 1.1185 - acc: 0.6058\n",
      "Epoch 45/150\n",
      "312/312 [==============================] - 22s 71ms/step - loss: 1.1020 - acc: 0.6089\n",
      "Epoch 46/150\n",
      "312/312 [==============================] - 22s 72ms/step - loss: 1.0973 - acc: 0.6086\n",
      "Epoch 47/150\n",
      "312/312 [==============================] - 22s 71ms/step - loss: 1.0944 - acc: 0.6097\n",
      "Epoch 48/150\n",
      "312/312 [==============================] - 22s 71ms/step - loss: 1.0874 - acc: 0.6173\n",
      "Epoch 49/150\n",
      "312/312 [==============================] - 22s 72ms/step - loss: 1.0783 - acc: 0.6190\n",
      "Epoch 50/150\n",
      "312/312 [==============================] - 22s 72ms/step - loss: 1.0685 - acc: 0.6216\n",
      "Epoch 51/150\n",
      "312/312 [==============================] - 23s 72ms/step - loss: 1.0768 - acc: 0.6190\n",
      "Epoch 52/150\n",
      "312/312 [==============================] - 22s 71ms/step - loss: 1.0675 - acc: 0.6259\n",
      "Epoch 53/150\n",
      "312/312 [==============================] - 22s 71ms/step - loss: 1.0594 - acc: 0.6275\n",
      "Epoch 54/150\n",
      "312/312 [==============================] - 22s 71ms/step - loss: 1.0559 - acc: 0.6254\n",
      "Epoch 55/150\n",
      "312/312 [==============================] - 22s 70ms/step - loss: 1.0518 - acc: 0.6264\n",
      "Epoch 56/150\n",
      "312/312 [==============================] - 22s 71ms/step - loss: 1.0389 - acc: 0.6339\n",
      "Epoch 57/150\n",
      "312/312 [==============================] - 22s 71ms/step - loss: 1.0397 - acc: 0.6344\n",
      "Epoch 58/150\n",
      "312/312 [==============================] - 23s 73ms/step - loss: 1.0354 - acc: 0.6368\n",
      "Epoch 59/150\n",
      "312/312 [==============================] - 22s 71ms/step - loss: 1.0320 - acc: 0.6374\n",
      "Epoch 60/150\n",
      "312/312 [==============================] - 22s 70ms/step - loss: 1.0241 - acc: 0.6428\n",
      "Epoch 61/150\n",
      "312/312 [==============================] - 22s 70ms/step - loss: 1.0228 - acc: 0.6402\n",
      "Epoch 62/150\n",
      "312/312 [==============================] - 22s 70ms/step - loss: 1.0149 - acc: 0.6458\n",
      "Epoch 63/150\n",
      "312/312 [==============================] - 22s 71ms/step - loss: 1.0083 - acc: 0.6448\n",
      "Epoch 64/150\n",
      "312/312 [==============================] - 22s 70ms/step - loss: 1.0125 - acc: 0.6419\n",
      "Epoch 65/150\n",
      "312/312 [==============================] - 22s 72ms/step - loss: 1.0081 - acc: 0.6473\n",
      "Epoch 66/150\n",
      "312/312 [==============================] - 22s 70ms/step - loss: 0.9991 - acc: 0.6489\n",
      "Epoch 67/150\n",
      "312/312 [==============================] - 22s 70ms/step - loss: 0.9972 - acc: 0.6519\n",
      "Epoch 68/150\n",
      "312/312 [==============================] - 22s 70ms/step - loss: 0.9975 - acc: 0.6506\n",
      "Epoch 69/150\n",
      "312/312 [==============================] - 22s 69ms/step - loss: 0.9887 - acc: 0.6535\n",
      "Epoch 70/150\n",
      "312/312 [==============================] - 22s 70ms/step - loss: 0.9868 - acc: 0.6557\n",
      "Epoch 71/150\n",
      "312/312 [==============================] - 22s 70ms/step - loss: 0.9819 - acc: 0.6537\n",
      "Epoch 72/150\n",
      "312/312 [==============================] - 23s 72ms/step - loss: 0.9729 - acc: 0.6570\n",
      "Epoch 73/150\n",
      "312/312 [==============================] - 22s 70ms/step - loss: 0.9720 - acc: 0.6618\n",
      "Epoch 74/150\n",
      "312/312 [==============================] - 22s 69ms/step - loss: 0.9707 - acc: 0.6600\n",
      "Epoch 75/150\n",
      "312/312 [==============================] - 22s 70ms/step - loss: 0.9585 - acc: 0.6653\n",
      "Epoch 76/150\n",
      "312/312 [==============================] - 22s 71ms/step - loss: 0.9686 - acc: 0.6606\n",
      "Epoch 77/150\n",
      "312/312 [==============================] - 22s 72ms/step - loss: 0.9636 - acc: 0.6628\n",
      "Epoch 78/150\n",
      "312/312 [==============================] - 22s 71ms/step - loss: 0.9547 - acc: 0.6668\n",
      "Epoch 79/150\n",
      "312/312 [==============================] - 22s 72ms/step - loss: 0.9564 - acc: 0.6659\n",
      "Epoch 80/150\n",
      "312/312 [==============================] - 22s 70ms/step - loss: 0.9474 - acc: 0.6705\n",
      "Epoch 81/150\n",
      "312/312 [==============================] - 22s 70ms/step - loss: 0.9410 - acc: 0.6713\n",
      "Epoch 82/150\n",
      "312/312 [==============================] - 22s 70ms/step - loss: 0.9419 - acc: 0.6700\n",
      "Epoch 83/150\n",
      "312/312 [==============================] - 22s 70ms/step - loss: 0.9472 - acc: 0.6669\n",
      "Epoch 84/150\n",
      "312/312 [==============================] - 22s 70ms/step - loss: 0.9391 - acc: 0.6735\n",
      "Epoch 85/150\n",
      "312/312 [==============================] - 22s 70ms/step - loss: 0.9324 - acc: 0.6769\n",
      "Epoch 86/150\n",
      "312/312 [==============================] - 23s 73ms/step - loss: 0.9373 - acc: 0.6732\n",
      "Epoch 87/150\n",
      "312/312 [==============================] - 22s 70ms/step - loss: 0.9267 - acc: 0.6751\n",
      "Epoch 88/150\n",
      "312/312 [==============================] - 22s 70ms/step - loss: 0.9295 - acc: 0.6764\n",
      "Epoch 89/150\n",
      "312/312 [==============================] - 22s 70ms/step - loss: 0.9273 - acc: 0.6777\n",
      "Epoch 90/150\n",
      "312/312 [==============================] - 22s 71ms/step - loss: 0.9179 - acc: 0.6812\n",
      "Epoch 91/150\n",
      "312/312 [==============================] - 22s 70ms/step - loss: 0.9137 - acc: 0.6811\n",
      "Epoch 92/150\n",
      "312/312 [==============================] - 22s 70ms/step - loss: 0.9120 - acc: 0.6828\n",
      "Epoch 93/150\n",
      "312/312 [==============================] - 22s 71ms/step - loss: 0.9147 - acc: 0.6820\n",
      "Epoch 94/150\n",
      "312/312 [==============================] - 22s 70ms/step - loss: 0.9159 - acc: 0.6807\n",
      "Epoch 95/150\n",
      "312/312 [==============================] - 22s 70ms/step - loss: 0.9055 - acc: 0.6834\n",
      "Epoch 96/150\n",
      "312/312 [==============================] - 22s 70ms/step - loss: 0.9014 - acc: 0.6851\n",
      "Epoch 97/150\n",
      "312/312 [==============================] - 22s 70ms/step - loss: 0.9021 - acc: 0.6828\n",
      "Epoch 98/150\n",
      "312/312 [==============================] - 22s 70ms/step - loss: 0.8994 - acc: 0.6881\n",
      "Epoch 99/150\n",
      "312/312 [==============================] - 22s 70ms/step - loss: 0.9002 - acc: 0.6886\n",
      "Epoch 100/150\n",
      "312/312 [==============================] - 23s 73ms/step - loss: 0.8910 - acc: 0.6882\n",
      "Epoch 101/150\n",
      "312/312 [==============================] - 22s 70ms/step - loss: 0.8912 - acc: 0.6877\n",
      "Epoch 102/150\n",
      "312/312 [==============================] - 22s 70ms/step - loss: 0.8853 - acc: 0.6925\n",
      "Epoch 103/150\n",
      "312/312 [==============================] - 22s 71ms/step - loss: 0.8774 - acc: 0.6950\n",
      "Epoch 104/150\n",
      "312/312 [==============================] - 22s 71ms/step - loss: 0.8867 - acc: 0.6929\n",
      "Epoch 105/150\n",
      "312/312 [==============================] - 22s 70ms/step - loss: 0.8788 - acc: 0.6922\n",
      "Epoch 106/150\n",
      "312/312 [==============================] - 22s 70ms/step - loss: 0.8785 - acc: 0.6949\n",
      "Epoch 107/150\n",
      "312/312 [==============================] - 22s 71ms/step - loss: 0.8724 - acc: 0.6968\n",
      "Epoch 108/150\n",
      "312/312 [==============================] - 22s 70ms/step - loss: 0.8803 - acc: 0.6954\n",
      "Epoch 109/150\n",
      "312/312 [==============================] - 22s 70ms/step - loss: 0.8703 - acc: 0.6980\n",
      "Epoch 110/150\n",
      "312/312 [==============================] - 22s 70ms/step - loss: 0.8682 - acc: 0.6940\n",
      "Epoch 111/150\n",
      "312/312 [==============================] - 22s 69ms/step - loss: 0.8613 - acc: 0.7043\n",
      "Epoch 112/150\n",
      "312/312 [==============================] - 22s 69ms/step - loss: 0.8641 - acc: 0.7009\n",
      "Epoch 113/150\n",
      "312/312 [==============================] - 22s 69ms/step - loss: 0.8702 - acc: 0.6990\n",
      "Epoch 114/150\n",
      "312/312 [==============================] - 22s 71ms/step - loss: 0.8630 - acc: 0.6978\n",
      "Epoch 115/150\n",
      "312/312 [==============================] - 22s 70ms/step - loss: 0.8625 - acc: 0.7008\n",
      "Epoch 116/150\n",
      "312/312 [==============================] - 22s 69ms/step - loss: 0.8629 - acc: 0.6994\n",
      "Epoch 117/150\n",
      "312/312 [==============================] - 22s 69ms/step - loss: 0.8583 - acc: 0.7004\n",
      "Epoch 118/150\n",
      "312/312 [==============================] - 22s 70ms/step - loss: 0.8484 - acc: 0.7061\n",
      "Epoch 119/150\n",
      "312/312 [==============================] - 22s 69ms/step - loss: 0.8490 - acc: 0.7050\n",
      "Epoch 120/150\n",
      "312/312 [==============================] - 22s 69ms/step - loss: 0.8502 - acc: 0.7049\n",
      "Epoch 121/150\n",
      "312/312 [==============================] - 22s 71ms/step - loss: 0.8423 - acc: 0.7077\n",
      "Epoch 122/150\n",
      "312/312 [==============================] - 22s 69ms/step - loss: 0.8359 - acc: 0.7102\n",
      "Epoch 123/150\n",
      "312/312 [==============================] - 22s 69ms/step - loss: 0.8392 - acc: 0.7111\n",
      "Epoch 124/150\n",
      "312/312 [==============================] - 21s 69ms/step - loss: 0.8382 - acc: 0.7080\n",
      "Epoch 125/150\n",
      "312/312 [==============================] - 22s 70ms/step - loss: 0.8340 - acc: 0.7110\n",
      "Epoch 126/150\n",
      "312/312 [==============================] - 22s 70ms/step - loss: 0.8293 - acc: 0.7105\n",
      "Epoch 127/150\n",
      "312/312 [==============================] - 23s 72ms/step - loss: 0.8356 - acc: 0.7073\n",
      "Epoch 128/150\n",
      "312/312 [==============================] - 22s 71ms/step - loss: 0.8355 - acc: 0.7122\n",
      "Epoch 129/150\n",
      "312/312 [==============================] - 23s 73ms/step - loss: 0.8308 - acc: 0.7144\n",
      "Epoch 130/150\n",
      "312/312 [==============================] - 22s 71ms/step - loss: 0.8213 - acc: 0.7148\n",
      "Epoch 131/150\n",
      "312/312 [==============================] - 22s 72ms/step - loss: 0.8257 - acc: 0.7153\n",
      "Epoch 132/150\n",
      "312/312 [==============================] - 23s 73ms/step - loss: 0.8276 - acc: 0.7134\n",
      "Epoch 133/150\n",
      "312/312 [==============================] - 22s 72ms/step - loss: 0.8285 - acc: 0.7150\n",
      "Epoch 134/150\n",
      "312/312 [==============================] - 23s 72ms/step - loss: 0.8182 - acc: 0.7170\n",
      "Epoch 135/150\n",
      "312/312 [==============================] - 23s 73ms/step - loss: 0.8167 - acc: 0.7169\n",
      "Epoch 136/150\n",
      "312/312 [==============================] - 23s 72ms/step - loss: 0.8142 - acc: 0.7170\n",
      "Epoch 137/150\n",
      "312/312 [==============================] - 22s 72ms/step - loss: 0.8109 - acc: 0.7198\n",
      "Epoch 138/150\n",
      "312/312 [==============================] - 22s 72ms/step - loss: 0.8144 - acc: 0.7181\n",
      "Epoch 139/150\n",
      "312/312 [==============================] - 22s 71ms/step - loss: 0.8071 - acc: 0.7205\n",
      "Epoch 140/150\n",
      "312/312 [==============================] - 22s 71ms/step - loss: 0.8149 - acc: 0.7150\n",
      "Epoch 141/150\n",
      "312/312 [==============================] - 22s 71ms/step - loss: 0.8074 - acc: 0.7211\n",
      "Epoch 142/150\n",
      "312/312 [==============================] - 23s 74ms/step - loss: 0.8025 - acc: 0.7205\n",
      "Epoch 143/150\n",
      "312/312 [==============================] - 23s 74ms/step - loss: 0.8095 - acc: 0.7193\n",
      "Epoch 144/150\n",
      "312/312 [==============================] - 23s 74ms/step - loss: 0.8000 - acc: 0.7245\n",
      "Epoch 145/150\n",
      "312/312 [==============================] - 23s 73ms/step - loss: 0.8009 - acc: 0.7228\n",
      "Epoch 146/150\n",
      "312/312 [==============================] - 22s 72ms/step - loss: 0.7951 - acc: 0.7244\n",
      "Epoch 147/150\n",
      "312/312 [==============================] - 22s 72ms/step - loss: 0.7989 - acc: 0.7235\n",
      "Epoch 148/150\n",
      "312/312 [==============================] - 23s 75ms/step - loss: 0.7959 - acc: 0.7229\n",
      "Epoch 149/150\n",
      "312/312 [==============================] - 22s 72ms/step - loss: 0.7907 - acc: 0.7250\n",
      "Epoch 150/150\n",
      "312/312 [==============================] - 22s 72ms/step - loss: 0.7975 - acc: 0.7242\n"
     ]
    }
   ],
   "source": [
    "history = final_model.fit_generator(datagen.flow(x_train, y_train_vec, batch_size=batch_size),\n",
    "                              steps_per_epoch=steps_per_epoch,\n",
    "                              epochs=150)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Evaluate the model on the test set\n",
    "\n",
    "Do NOT used the test set until now. Make sure that your model parameters and hyper-parameters are independent of the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 114us/step\n",
      "loss = 0.7581720972061157\n",
      "accuracy = 0.7334\n"
     ]
    }
   ],
   "source": [
    "loss_and_acc = final_model.evaluate(x_test, y_test_vec)\n",
    "print('loss = ' + str(loss_and_acc[0]))\n",
    "print('accuracy = ' + str(loss_and_acc[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
